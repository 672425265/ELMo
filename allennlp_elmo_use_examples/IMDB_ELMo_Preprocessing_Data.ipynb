{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Keras_ELMo_Tutorial Preprocessing](https://github.com/UKPLab/elmo-bilstm-cnn-crf/blob/master/Keras_ELMo_Tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.layers import Embedding\n",
    "from keras.initializers import Constant\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner', 'textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 100000\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "EMBEDDING_DIM = 100\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data: http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "train_data_df = pd.read_csv('data/imdb_train_pandas_datafram.csv')\n",
    "test_data_df = pd.read_csv('data/imdb_test_pandas_datafram.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This film is notable for three reasons.  First...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Escaping the life of being pimped by her fathe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wenders was great with Million $ Hotel.I don't...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saw this in the theater in '86 and fell out of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A terrible amateur movie director (no, not Tod...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  This film is notable for three reasons.  First...      0\n",
       "1  Escaping the life of being pimped by her fathe...      1\n",
       "2  Wenders was great with Million $ Hotel.I don't...      0\n",
       "3  Saw this in the theater in '86 and fell out of...      1\n",
       "4  A terrible amateur movie director (no, not Tod...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 英文分词\n",
    "def use_spacy_segmented_words(a_text_sentence):\n",
    "    doc = nlp(a_text_sentence)\n",
    "    token_list = [token for token in doc]\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把cut_text 处理成定长\n",
    "def padding_cut_text(datafram_cut_text, MAX_SEQUENCE_LENGTH=MAX_SEQUENCE_LENGTH):\n",
    "    raw_cut_text_len = len(datafram_cut_text)\n",
    "    if raw_cut_text_len >= MAX_SEQUENCE_LENGTH:\n",
    "        return datafram_cut_text[:MAX_SEQUENCE_LENGTH]\n",
    "    else:\n",
    "        datafram_cut_text += [\"\" for _ in range(MAX_SEQUENCE_LENGTH - raw_cut_text_len)] \n",
    "        return datafram_cut_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离特征文本和标签\n",
    "def slipe_text_label(data_pandas_datafram):\n",
    "    x_list, label_list = [], []\n",
    "    for row_index, a_row in data_pandas_datafram.iterrows():\n",
    "        raw_text = a_row[0]\n",
    "        raw_cut_text = use_spacy_segmented_words(raw_text)\n",
    "        raw_cut_padding_text = padding_cut_text(raw_cut_text)\n",
    "        raw_cut_padding_text = [str(x) for x in raw_cut_padding_text]\n",
    "        x_list.append(raw_cut_padding_text)\n",
    "        label_list.append(a_row[1])\n",
    "    return x_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_x_train, raw_y_train = slipe_text_label(train_data_df)\n",
    "\n",
    "raw_x_test, raw_y_test = slipe_text_label(test_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "# https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\n",
    "# https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\n",
    "options_file = \"/home/b418/jupyter_workspace/yuanxiao/elmo_data/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\"\n",
    "weight_file = \"/home/b418/jupyter_workspace/yuanxiao/elmo_data/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\"\n",
    "\n",
    "elmo = ElmoEmbedder(options_file, weight_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ":: Lookup of 100 ELMo representations. This takes a while ::\n",
      "100%[==================================================] 100/100 sentences\n",
      "\n",
      ":: Lookup of 100 ELMo representations. This takes a while ::\n",
      "100%[==================================================] 100/100 sentences"
     ]
    }
   ],
   "source": [
    "# Lookup the ELMo embeddings for all documents (all sentences) in our dataset. Store those\n",
    "# in a numpy matrix so that we must compute the ELMo embeddings only once.\n",
    "def create_elmo_embeddings(elmo, documents, max_sentences = 1000):\n",
    "    num_sentences = min(max_sentences, len(documents)) if max_sentences > 0 else len(documents)\n",
    "    print(\"\\n\\n:: Lookup of \"+str(num_sentences)+\" ELMo representations. This takes a while ::\")\n",
    "    embeddings = []\n",
    "    documentIdx = 0\n",
    "    for elmo_embedding in elmo.embed_sentences(documents):  \n",
    "        document = documents[documentIdx]\n",
    "        # 取第三个向量的值\n",
    "        third_elmo_embedding = elmo_embedding[2]    \n",
    "        embeddings.append(third_elmo_embedding)            \n",
    "        # Some progress info\n",
    "        documentIdx += 1\n",
    "        percent = 100.0 * documentIdx / num_sentences\n",
    "        line = '[{0}{1}]'.format('=' * int(percent / 2), ' ' * (50 - int(percent / 2)))\n",
    "        status = '\\r{0:3.0f}%{1} {2:3d}/{3:3d} sentences'\n",
    "        sys.stdout.write(status.format(percent, line, documentIdx, num_sentences))\n",
    "        \n",
    "        if max_sentences > 0 and documentIdx >= max_sentences:\n",
    "            break       \n",
    "    return embeddings\n",
    "\n",
    "\n",
    "x_train_elmo = create_elmo_embeddings(elmo, raw_x_train[:100], 100)\n",
    "x_text_elmo = create_elmo_embeddings(elmo, raw_x_test[:100], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_text_elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_elmo_1 = np.array(x_train_elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_text_elmo_1 = np.array(x_text_elmo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对齐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(raw_y_train[:100])\n",
    "y_test = np.array(raw_y_test[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设计模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_elmo_v1_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=250, kernel_size=3, padding='same', input_shape=(MAX_SEQUENCE_LENGTH,1024)))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    plot_model(model, \n",
    "               to_file=\"IMDB_ELMo_Preprocessing.png\",\n",
    "               show_shapes=True)\n",
    "    model.compile(\n",
    "              loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "creat_elmo_v1_model = creat_elmo_v1_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 3.4737 - acc: 0.5125 - val_loss: 2.6278 - val_acc: 0.5500\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 1.1564 - acc: 0.7375 - val_loss: 2.7299 - val_acc: 0.6000\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.0570 - acc: 0.9875 - val_loss: 1.0813 - val_acc: 0.6500\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 1.3546 - val_acc: 0.6500\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.1732 - val_acc: 0.6500\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 3.5181e-04 - acc: 1.0000 - val_loss: 1.1210 - val_acc: 0.6500\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 2.8659e-04 - acc: 1.0000 - val_loss: 1.1081 - val_acc: 0.6500\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 2.5671e-04 - acc: 1.0000 - val_loss: 1.0804 - val_acc: 0.6000\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 2.2657e-04 - acc: 1.0000 - val_loss: 1.0583 - val_acc: 0.7000\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 2s 24ms/step - loss: 2.0326e-04 - acc: 1.0000 - val_loss: 1.0598 - val_acc: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa61ead44e0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creat_elmo_v1_model.fit(x_train_elmo_1, y_train,\n",
    "          batch_size=2,\n",
    "          epochs=10,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1400712180137633, 0.66]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creat_elmo_v1_model.evaluate(x_text_elmo_1, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
